---
title: "Enzyme utilization and saturation for *R. eutropha*"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_notebook: 
    theme: spacelab
    toc: yes
---


## Description

This R notebook is a bioinformatics pipeline to **analyze protein saturation/under-utilization with a resource allocation model** for the chemolithoautotroph *Ralstonia eutropha* (a.k.a. *Cupriavidus necator*).


## Libraries

```{r, message = FALSE}
# loading libraries
library(lattice)
library(latticeExtra)
library(latticetools)
library(tidyverse)
library(stringi)
```

## Data import

Define the data source directories. Some of them are external in the sense of not included in the accompanying data folder of this R notebook. These are located in the accompanying github repository for the resource allocation model that was used here. The resource allocation model can be found at my fork of [Bacterial-RBA-models](https://github.com/m-jahn/Bacterial-RBA-models).

```{r, message = FALSE}
Reutropha_proteomics <- "~/Documents/SciLifeLab/Resources/R_projects/ShinyProt/data/Ralstonia_eutropha.Rdata"
model_reactions <- "~/Documents/SciLifeLab/Resources/Models/genome-scale-models/Ralstonia_eutropha/simulations/essentiality/model_reactions.csv"
simulation_dir <- "~/Documents/SciLifeLab/Resources/Models/Bacterial-RBA-models/Ralstonia-eutropha-H16/simulation/substrate_limitation/"
source("read_rba_result.R")
```


Read simulation data.

```{r}
# read simulation results
df_flux <- read_rba_result(list.files(simulation_dir, pattern = "fluxes_.*.tsv$", full.names = TRUE))
df_prot <- read_rba_result(list.files(simulation_dir, pattern = "proteins_.*.tsv", full.names = TRUE))
df_macr <- read_rba_result(list.files(simulation_dir, pattern = "macroprocesses_.*.tsv", full.names = TRUE))
```


## Overview on substrate uptake, growth, and yield

After running a set of simulations in RBApy that simulate increasing substrate limitation, we can plot the substrate uptake rate `q`, yield `Y` in gram biomass per gram substrate, and growth rate `µ`. Unlike genome scale models, growth becomes limited by the maximum amount of proteins that a cell can synthesize. If cells would not be protein-limited, *or* proteins would catalyze reactions infinitely fast, no such limitation would take place and growth rate would scale linearly with substrate concentration. This is the situation in FBA simulation.

```{r, fig.width = 6.7, fig.height = 6.7, message = FALSE, warning = FALSE}
# add g per gDCW uptake rate
df_macr <- df_macr %>% mutate(
  substrate_conc_g = case_when(
    carbon_source == "for" ~ carbon_conc * 0.04603,
    carbon_source == "succ" ~ carbon_conc * 0.11809,
    carbon_source == "fru" & nitrogen_conc == 1 ~ carbon_conc * 0.18016,
    carbon_source == "fru" & nitrogen_conc != 1 ~ nitrogen_conc * 0.05349
  )
)

# Herbet-Pirt-plot function to create plots using different parameters
HP_plot <- function(data, xvar, yvar, condvar, 
  xlimits = c(0, 0.3), ylimits = c(0, 1)
) {
  xyplot(get(yvar) ~ get(xvar) | get(condvar), data,
    par.settings = custom.colorblind(), lwd = 1.5,
    xlim = xlimits, ylim = ylimits,
    ylab = expression("q"[S]*" [g h"^-1*" gDCW"^-1*"]"),
    xlab = expression('µ [h'^'-1'*']'),
    panel = function(x, y, ...) {
      panel.grid(h = -1, v = -1, col = grey(0.9))
      panel.xyplot(x, y, cex = 0.9, ...)
      # regression line through linear part of the data
      panel.lmlineq(x, y, fontfamily = "FreeSans", 
        pos = 3, offset = 7, r.squared = TRUE, cex = 0.7, col.text = grey(0.3), ...)
      coef <- lm(y ~ x, data.frame(x, y))$coeff
      # displaying maintenance and yield coefficients
      panel.abline(h = coef[[1]], lty = 2, ...)
      panel.text(0.15, coef[[1]], 
        paste("ms =", round(coef[[1]], 3), "g h-1 g_DCW-1"), 
        col = grey(0.3), pos = 3, cex = 0.7)
      panel.text(0.15, coef[[1]], paste(expression("Yx/S ="), 
          round(1/coef[[2]], 3), "g_DCW g_S-1"), 
        col = grey(0.3), pos = 1, cex = 0.7)
    }
  )
}

print(HP_plot(data = filter(df_macr, carbon_source == "for", key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "carbon_source", 
  ylimits = c(-5/4, 5)), split = c(1,1,2,2), more = TRUE)

print(HP_plot(data = filter(df_macr, carbon_source == "fru" & nitrogen_conc == 1, key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "carbon_source",
  ylimits = c(-1/4, 1)), split = c(2,1,2,2), more=TRUE)

print(HP_plot(data = filter(df_macr, carbon_source == "fru" & nitrogen_conc != 1, key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "nitrogen_source",
  ylimits = c(-0.23/4, 0.15)), split = c(1,2,2,2), more = TRUE)

print(HP_plot(data = filter(df_macr, carbon_source == "succ", key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "carbon_source",
  ylimits = c(-1/4, 1)), split = c(2,2,2,2))
```


```{r, include = FALSE}
# export figure
svg("../figures/figure_substrate_limitation.svg", width = 6.7, height = 6.7)
print(HP_plot(data = filter(df_macr, carbon_source == "for", key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "carbon_source", 
  ylimits = c(-5/4, 5)), split = c(1,1,2,2), more = TRUE)

print(HP_plot(data = filter(df_macr, carbon_source == "fru" & nitrogen_conc == 1, key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "carbon_source",
  ylimits = c(-1/4, 1)), split = c(2,1,2,2), more=TRUE)

print(HP_plot(data = filter(df_macr, carbon_source == "fru" & nitrogen_conc != 1, key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "nitrogen_source",
  ylimits = c(-0.23/4, 0.15)), split = c(1,2,2,2), more = TRUE)

print(HP_plot(data = filter(df_macr, carbon_source == "succ", key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "carbon_source",
  ylimits = c(-1/4, 1)), split = c(2,2,2,2))
dev.off()
```


## Resource allocation in terms of protein mass

To determine the true allocation of protein resources per compartment, but also the true cost of protein per process, we need to **convert the predicted concentration of proteins in mmol per gDCW to g per gDCW**, simply by multiplying protein concentration with the molecular weight of a protein (g/mol, converted to g/mmol). We can then also easily transform g/gDCW to mass fraction by dividing individual protein concentrations by the sum of all protein concentrations. The protein mass fraction is dimensionless. The only parameter required for this transformation is the molecular weight per protein which is available from uniprot. We can for example take the protein annotation table that is automatically downloaded during `RBApy` model generation.

```{r, message = FALSE}
# import downloaded Ralstonia protein annotation from uniprot
df_uniprot <- read_tsv(paste0(simulation_dir, "../../data/uniprot.csv"), col_types = cols()) %>%
  mutate(locus_tag = stri_extract_first(`Gene names`, regex = "H16_[AB][0-9]{4}|PHG[0-9]{3}"))

# merge predicted protein allocation with molecular weight info from uniprot
df_prot <- left_join(df_prot, select(df_uniprot, locus_tag, Length, Mass),
  by = c("key" = "locus_tag")) %>%
  
  # calculate predicted protein mass in g/gDCW using MW in g/mmol, and mass fraction
  group_by(simulation) %>% mutate(
    predicted_mass_g_gDCW = value * Mass / 1000)

# test if mass fractions sum to reasonable value
df_prot %>% summarize(
  predicted_mass_g_gDCW = sum(predicted_mass_g_gDCW, na.rm = TRUE))
```

----------

The simulated protein mass per gDCW changes with growth rate, and it is considerably lower then the estimated ~0.65 g total protein/gDCW that was previously estimated for bacteria (see e.g. Park et al., biomass composition for *Ralstonia eutropha* model, or Touloupakis et al., biomass composition for cyanobacteria). One reason is that above numbers only include enzymatic proteins (the ones represented by the GSM). For machinery such as ribosomal proteins, a separate calculation needs to be performed. The model returns estimated concentration of machineries for replication, transcription, translation, and protein folding. The associated proteins can be imported from the model folder and the total mass estimated using molecular weight and subunit stoichiometry as done before for enzymatic proteins.

```{r, message = FALSE}
machinery_names <- c("replication", "transcription", "ribosome", "chaperones")
machinery_tables <- paste0(simulation_dir, "../../data/", machinery_names, ".tsv")

df_macr <- df_macr %>% group_by(simulation) %>%
  mutate(
    key = recode(key, !!!setNames(machinery_names, c("P_REP", "P_TSC" , "P_TA", "P_CHP"))),
    substrate_uptake_rate = value[key == "qS"],
    predicted_growth_rate = value[key == "mu"],
  )

df_machinery <- lapply(machinery_tables, read_tsv) %>% bind_rows(.id = "machine") %>%
  mutate(machine = recode(machine, !!!setNames(machinery_names, 1:4))) %>%
  select(-`Entry name`, -Sequence, -Cofactor, -`EC number`, -`Organism ID`, `Organism`,
    -`Catalytic activity`, -Status) %>%
  
  # join with prediction of molecular machine concentration (mmol/gDCW)
  left_join(df_macr, by = c("machine" = "key")) %>%
  
  # calculate predicted protein mass in g/gDCW using MW in g/mmol, and mass fraction
  group_by(simulation) %>% mutate(
    predicted_mass_g_gDCW = value * Stoichiometry * Mass / 1000
  )

# test if mass fractions sum to reasonable value
df_machinery %>% summarize(
  sum_g_gDCW = sum(predicted_mass_g_gDCW, na.rm = TRUE))
```

If the utilized protein for enzymes and machinery is summed up, it does not exceed ~0.25 g/gDCW. The reason for this is that up to 60% of the protein mass is not modeled (non enzymatic, NE proteome, 57.7% at µ = 0, see R notebook `Ralstonia-model-constraints`), and only around 65% of the total cell mass is protein. If we consider this, than total protein mass can be estimated as m = 0.25/(1-0.6) = `r round(0.25/(1-0.6), 3)` g/gDCW. This is much closer to the estimated 0.65 g protein/gDCW. The difference can be attributed to default values of amino acid concentration in `RBApy` that determine the size of the 'protein pool'. It is important to note that the sum of utilizable proteins is not a constant value but a linear function of growth rate. The total proteome pool *including non-enzymatic proteins* is, however, constant.


## Correlation between predicted and experimentally determined proteome

To compare the predicted and experimental proteome composition, we load the required proteomics data. Proteomics data are mass spectrometry measurements with label-free quantification of peptides. Protein quantification was performed by summing up all peptide intensities per annotated protein. The proteomic measurement unit, mass fraction, can be easily transformed to g/gDCW by multiplying mass fraction with the total protein mass (g/gDCW) from the RBApy simulation. Or *vice versa* by converting RBApy protein concentration to mass fraction.

To allow a fair comparison between measured and predicted data, it is necessary to aggregate (e.g. sum up) all protein abundances allocated of one reaction. The reason is that the model will only predict **protein abundance of the first of a range of iso-enzymes** for a particular reaction, while in reality another iso-enzyme might be more abundant (carry the majority of flux). This would lead to lower correlation between measured and predicted protein concentrations. This is not necessary for machinery proteins.


### Combine simulations and experimental data

The proteomics data has to be merged with `RBApy` simulation results using matching conditions. First, proteomics data has to be loaded and prepared for merging.


**Step 1: load proteomics data**

```{r}
load(Reutropha_proteomics)

# pick a condition matching simulations
Ralstonia_eutropha <- Ralstonia_eutropha %>%
  
  # select only required columns
  rename(growth_rate = growthrate) %>%
  select(uniprot, locus_tag, protein, condition, substrate, substrate_uptake_rate,
    growth_rate, COG_Process, R1:R4) %>%
  
  # turn raw intensity measurements into mass in g per gDCW (assuming a 
  # total protein concentration of 0.65 g/gDCW)
  mutate(across(matches("R[1234]"), function(x) x/sum(x, na.rm = TRUE)*0.65)) %>%
  gather(key = "replicate", value = "mass_g_gDCW", R1:R4)
```


**Step 2: Load gene reaction associations obtained from genome scale model**

```{r, warning = FALSE}
df_model_reactions <- read_csv(model_reactions, col_types = cols()) %>%
  
  # filter for reactions with gene associations
  select(reaction_id, reaction_name, genes) %>% separate_rows(genes, sep = ", ") %>%
  filter(!is.na(genes))
```


**Step 3: Select and rename conditions from RBA simulation**

```{r}
# add type of substrate limitation
add_cond <- function(df) {
  df %>% mutate(substrate = case_when(
    carbon_source == "succ" ~ "succinate",
    carbon_source == "for" ~ "formate",
    carbon_source == "fru" & nitrogen_conc == 1 ~ "fructose",
    TRUE ~ "ammonium",
  ))
}

# add substrate uptake rate
add_qS <- function(df) {
  df %>% mutate(substrate_uptake_rate = case_when(
    nitrogen_conc == 1 ~ carbon_conc,
    nitrogen_conc != 1 ~ nitrogen_conc
  ))
}

df_machinery <- df_machinery %>% add_cond
df_prot <- df_prot %>% add_cond %>% add_qS
df_flux <- df_flux %>% add_cond %>% add_qS
```


**Step 4: Merge protein measurements and predictions into master tables**

The first step is to merge the tables for machinery proteins, that means proteins related to replication, transcription, translation, and protein folding. These don't require allocation of protein mass to reactions, and merging becomes simply an operation on enzyme IDs and conditions.

```{r}
# join with proteomics data
df_machinery <- left_join(
  df_machinery, Ralstonia_eutropha,
  by = c("Entry" = "uniprot", "substrate", "substrate_uptake_rate"))
```

The second table for all enzymatic proteins requires the allocation of estimated protein mass to enzymes.
One option for the future is to retrieve these values directly from RBApy, but this is not implemented yet.

```{r, message = FALSE}
df_prot_comp <- df_model_reactions %>%
  
  # join with proteomics data
  left_join(Ralstonia_eutropha, by = c("genes" = "locus_tag")) %>%
  
  # join with simulation data
  left_join(df_prot, by = c("genes" = "key", "substrate", "substrate_uptake_rate")) %>%
  
  # determine number of reactions per protein
  group_by(condition, genes, replicate) %>% 
  mutate(n_reactions = length(reaction_id)) %>%
  
  # calculate mass fractions
  group_by(condition) %>% mutate(
    predicted_mass_g_gDCW = predicted_mass_g_gDCW/n_reactions,
    mass_g_gDCW = mass_g_gDCW/n_reactions
  ) %>%
  
  # summarize by summing up protein abundance per reaction (NA treated as zero)
  group_by(condition, reaction_id, reaction_name, substrate, substrate_uptake_rate,
    growth_rate, replicate) %>% 
  summarize(
    predicted_mass_g_gDCW = sum(predicted_mass_g_gDCW, na.rm = TRUE),
    mass_g_gDCW = sum(mass_g_gDCW, na.rm = TRUE)
  ) %>%
  
  # add predicted growth rate to experimental
  left_join(
    df_machinery %>% ungroup %>%
    select(substrate, substrate_uptake_rate, predicted_growth_rate) %>%
    filter(!duplicated(substrate_uptake_rate))
  ) %>%
  
  # add predicted fluxes per reaction and condition
  left_join(
    df_flux %>% ungroup %>%
    select(key, value, substrate, substrate_uptake_rate) %>%
    rename(reaction_id = key, flux_mmol_gDCW_h = value)
  )
```

Now we perform a test. We check if all protein abundances allocated to reactions sum to a reasonable value as we would expect. This value would be the total *enzymatic* protein mass in g/gDCW, per condition and replicate, and could reach up to 0.2 g/gDCW for the simulations, and higher for the actual data (includes additional protein quantified in experiment, but not carrying flux in model simulations).

```{r, message = FALSE}
df_prot_comp %>% group_by(condition, replicate) %>% 
  filter(predicted_mass_g_gDCW != 0) %>%
  summarize(sum(mass_g_gDCW), sum(predicted_mass_g_gDCW))
```

----------

The total predicted protein mass is lower than the measured protein mass. Therefore the following section quantifies discrepancies between model predicted and actually measured abundances. First we can inspect the top N reactions with highest **average predicted protein abundance**. The ratio of predicted divided by measured mass indicates that a handful of proteins are predicted to be more than 10 fold abundant compared to the measured abundance. This points towards fluxes being erroneously predicted too high for particular reactions, or *k_app* values being estimated too low for the estimated flux. 

However, the largest discrepancies arise from **under-estimation of proteins**, the main cause being that the model predicts the **optimal abundance for each enzyme to carry a certain flux** (see following figure, comparison of simulation and experiment). If fluxes are drastically reduced due to strong substrate limitation, the minimal required protein abundance to optimize growth will be much lower than the measured abundance. The cell on the other hand does not reduce it's proteome but instead 'suspends' enzymes.


```{r, message = FALSE, fig.height = 8, fig.width = 8}
# Proteins 'over-predicted' by more than 10x are rare
df_prot_comp %>% group_by(reaction_id, substrate) %>%
  summarize(
    average_predicted_mass = mean(predicted_mass_g_gDCW),
    average_measured_mass = mean(mass_g_gDCW),
    overprediction_fold = round(average_predicted_mass/average_measured_mass)) %>%
  arrange(desc(overprediction_fold)) %>% filter(overprediction_fold > 10)

# comparison of simulation and experiment
df_prot_comp %>% group_by(reaction_id, substrate, growth_rate) %>%
  summarize(predicted_mass_g_gDCW = mean(predicted_mass_g_gDCW),
    mass_g_gDCW = mean(mass_g_gDCW)
  ) %>%
  
  xyplot(log10(predicted_mass_g_gDCW) ~ log10(mass_g_gDCW) | factor(growth_rate) * substrate, .,
    groups = substrate,
    par.settings = custom.colorblind(), cex = 0.7,
    scales = list(alternating = FALSE), as.table = TRUE,
    between = list(x = 0.5, y = 0.5), 
    pch = 1, xlim = c(-8.5, -0.5), ylim = c(-8.5, -0.5),
    panel = function(x, y, ...) {
      panel.grid(h = -1, v = -1, col = grey(0.9))
      panel.abline(a = 0, b = 1, col = grey(0.5), lty = 2, lwd = 2)
      panel.xyplot(x, y, ...)
    }
  )
```

### Change of machinery proteins over growth rate

The simulation and measurement data was prepared and merged by condition in the previous sections. Now it can be plotted to e.g. compare protein allocation over growth rate. Interestingly, we see that model predictions are quite accurately reflecting the range of protein allocation for the four different machineries, see following paragraphs. This is a good confirmation of the model's predictive power, given that the rates of these machineries were not fitted from data but taken purely from literature.  There are however some deviations from the predicted 'optimal' proteome:

- the most important machine is the ribosome. Prediction and experiment show a very similar increase of ribosome abundance with growth rate, but the intersection (amount of unused ribosomes) is much higher in experiment
- chaperones show an inverse proportional relationship with growth rate contrary to model prediction. Do (some of?) these proteins have another role than just folding, like stress response?
- transcription sector is quite stable, however, requires more enzymes than expected. Abundance is underestimated by 1 order of magnitude (5x10^-3 vs 5x10^-4 g/gDCW)
- replication sector is heavily underestimated by 3 orders of magnitude (10^-3 vs 10^-6 g/gDCW)

The following code section gathers growth rate/mass measurements and predictions in a single column each. This is better for summarizing and plotting.

```{r, echo = FALSE}
# A generalized plotting function to save some repetition
xyplot_errbars <- function(
  data, variables, groups = NULL,
  xlim = NULL, ylim = NULL,
  xlab = expression("µ [h"^-1*"]"),
  ylab = expression("m"[protein]*" [g gDCW"^-1*"]")) {
  
  scaleoptions <- list(alternating = FALSE)
  if (!is.null(xlim)) scaleoptions$x = list(limits = xlim)
  if (!is.null(ylim)) scaleoptions$y = list(limits = ylim)
  
  xyplot(as.formula(variables), data,
    groups = {if (!is.null(groups)) get(groups) else NULL},
    par.settings = custom.colorblind(),
    scales = scaleoptions, as.table = TRUE,
    between = list(x = 0.5, y = 0.5),
    pch = 19, lwd = 2, 
    xlab = xlab, ylab = ylab,
    panel = function(x, y, ...) {
      panel.grid(h = -1, v = -1, col = grey(0.9))
      panel.errbars(x, y, ewidth = 0, ...)
      panel.key(..., cex = 0.7)
      panel.superpose(x, y, ...)},
    panel.groups = function(x, y, ...) {
      panel.lmline(x, y, ...)
    }
  )
}
```

```{r, message = FALSE, fig.width = 6, fig.height = 6.8}
df_machinery %>%
  
  # summing up protein mass over all conditions
  group_by(machine, substrate, growth_rate, replicate) %>%
  summarize(
    mass_g_gDCW = sum(mass_g_gDCW, na.rm = TRUE),
    predicted_mass_g_gDCW = sum(predicted_mass_g_gDCW, na.rm = TRUE)
  ) %>%
  
  # replace 0 with NA and reorder factors
  mutate(across(matches("mass_g_gDCW"), ~ na_if(.x, 0))) %>%
  mutate(machine = factor(machine, unique(machine)[c(2,4,3,1)])) %>%
  
  xyplot_errbars(
    variables = "mass_g_gDCW + predicted_mass_g_gDCW ~ 
      factor(growth_rate) | machine * substrate"
  )
```
The increase of chaperone proteins with decreasing growth rate is counter-intuitive, and the underlying cause might be the inclusion or exclusion of particular proteins in this group. We want to include mostly chaperones related to the primary ribosome-supporting task of polypeptide chain folding after translation. Chaperones that are mostly related to stress-resistance or environmental resilience should be excluded (upregulated under substrate limitation?). The following plot shows abundance over growth rate for single proteins within a machinery, such as chaperones.

```{r, fig.width = 8, fig.height = 4, fig.align = "center"}
xyplot_errbars(
  data = df_machinery %>% filter(machine == "chaperones"),
  variables = "mass_g_gDCW ~ factor(growth_rate) | substrate",
  groups = "protein"
)
```

### Change of enzymatic proteins over growth rate

Similar to machinery proteins we can also follow the simulation and actual protein abundance of all (detected) enzymes. The first step is to construct different **groups of interesting reactions** that can be inspected closer.


```{r}
# construct groups of central metabolism genes
glycolysis = c("HEXf", "PGI", "G6PDH2r", "PGL", "EDD", "EDA", "FBA", 
  "GAPD", "PGK", "PGM", "ENO")
pyruvate = c("PPS", "PYK", "PDH1", "PDH2", "PDH3", "PC", "PPC", "PPCK")
tca = c("CS", "ACONT1", "ICDHx", "AKGDH", "SUCOAS", "SUCDi", "FUM", "MDH")
calvin = c("FDH", "RBPC", "PGK", "GAPD", "TPI", "FBA", "FBP", "TKT2", "TKT1", "TAh", "RPE", "RPI")
```

The next step is to have a generalized plotting function that can plot simulated and measured protein abundance including error bars. We can see that some protein abundances nicely follow a growth-rate dependent manner, in line with predictions of higher flux. One such example are Calvin cycle enzymes for fromatotrophic growth. However, for the same enzymes we see that no abundance is predicted under heterotrophic conditions because of missing flux through the pathway, but in fact the proteins are expressed in high abundance, often in a growth-rate dependent manner. What is also puzzling is abundances for most enzymes are actually under-predicted. Since the total amount of enzymatic protein is comparable (but not identical) for simulations and measurements, we also have to investigate over-predicted protein abundances.

```{r, message = FALSE, fig.width = 9, fig.height = 5.5}
# Plot Calvin cycle reactions
xyplot_errbars(
  data = df_prot_comp %>% filter(reaction_id %in% calvin),
  variables = "mass_g_gDCW + predicted_mass_g_gDCW ~ 
    factor(growth_rate) | reaction_id * substrate",
  ylim = c(-0.002, 0.032)
)

# Plot TCA cycle reactions
xyplot_errbars(
  data = df_prot_comp %>% filter(reaction_id %in% tca),
  variables = "mass_g_gDCW + predicted_mass_g_gDCW ~ 
    factor(growth_rate) | reaction_id * substrate",
  ylim = c(-5*10^-4, 6*10^-3)
)
```

----------

## Determining under-utilization of proteins

It is clear from the previous analysis that the cells maintain proteins even if they are not or only marginally utilized. The actually utilized proteome is minimal under strong substrate limitation. The next section will try to quantify the **under-utilization of enzymes** by determining e.g. the flux per enzyme and compare minimal protein requirement (simulation) versus measured protein abundance.

A second option is to simply compare **trends in enzyme saturation** and derive conclusions about the underlying regulation of enzyme abundance. We can think of the following scenarios:

- enzyme abundance shrinks or expands with growth rate/flux. Utilization is constant, protein allocation is optimized towards flux and may exert some control over a pathway
- enzyme abundance is constant, regardless of flux. Utilization increases with growth rate. 'Housekeeping' protein with non-limiting concentration, less probability for reaction control.
- mixed variants of the above. For example enzyme abundance is constant, utilization increases with growth rate, but only until a certain growth rate where abundance changes suddenly (on/off behavior)

Note that this analysis only includes enzymes that are **actually utilized by the model** under some condition, not all proteins included in the model or all experimentally quantified proteins. This is covered in the R notebook **Ralstonia_variability_analysis**.

### Under-utilization by protein abundance

For this branch of analysis, it is sufficient to determine the underutilized protein fraction (of all utilized proteins) by subtracting the simulated optimal protein allocation from the experimentally measured.

```{r, message = FALSE, fig.width = 9, fig.height = 5.5}
df_prot_comp <- df_prot_comp %>%
  
  # calculate (un)-utilized protein mass and fraction
  mutate(
    unutilized_mass_g_gDCW = mass_g_gDCW - predicted_mass_g_gDCW,
    unutilized_mass_fraction = unutilized_mass_g_gDCW/mass_g_gDCW,
  )
```

----------

Plot under-utilized proteins by pathway.

```{r, message = FALSE, fig.width = 9, fig.height = 5.5}
xyplot_errbars(
  data = df_prot_comp %>% filter(reaction_id %in% calvin),
  variables = "unutilized_mass_g_gDCW ~ factor(growth_rate) | reaction_id * substrate",
  groups = "substrate", ylim = c(-0.003, 0.023)
)
```

----------

Plot of top 10 under-utilized proteins by mass. Included are only reactions that carry flux under at least one condition or growth rate (that means reactions that never carry flux in any simulation are removed).

```{r, message = FALSE, fig.width = 9, fig.height = 5.5}
df_prot_comp %>% group_by(reaction_id) %>%
  filter(sum(predicted_mass_g_gDCW) > 0) %>%
  mutate(average_unutilized_mass = mean(unutilized_mass_g_gDCW)) %>%
  filter(average_unutilized_mass > 0.00225) %>%
  
  xyplot_errbars(
    variables = "unutilized_mass_g_gDCW ~ factor(growth_rate) | reaction_id * substrate",
    groups = "substrate"
  )
```

Plot a summary of underutilized enzyme mass per condition. Included are only reactions that carry flux under at least one condition or growth rate (that means reactions that never carry flux in any simulation are removed).

```{r, fig.width = 6, fig.height = 5, message = FALSE}
df_prot_comp %>% group_by(reaction_id) %>%
  filter(sum(predicted_mass_g_gDCW) > 0) %>%
  
  # sum up underutilized mass per substrate and growth rate
  group_by(substrate, substrate_uptake_rate, growth_rate, replicate) %>%
  summarize(
    sum_underutilized_mass_g_gDCW = sum(unutilized_mass_g_gDCW, na.rm = TRUE),
    sum_utilized_mass_g_gDCW = sum(predicted_mass_g_gDCW, na.rm = TRUE)
  ) %>%
  
  #replace zero with NA
  mutate(sum_underutilized_mass_g_gDCW = sum_underutilized_mass_g_gDCW %>%
    replace(., . <= 0, NA)) %>%
  
  xyplot(sum_underutilized_mass_g_gDCW + sum_utilized_mass_g_gDCW ~ 
    factor(growth_rate) | substrate, .,
    par.settings = custom.colorblind(),
    xlab = bquote(µ*" [h"^-1*"]"),
    ylab = bquote("g gDCW"^-1),
    ylim = c(0, 0.27),
    scales = list(alternating = FALSE), as.table = TRUE,
    between = list(x = 0.5, y = 0.5), 
    ewidth = 0.15, beside = TRUE, lwd = 1.5,
    panel = function(x, y, errors, ...) {
      panel.grid(h = -1, v = -1, col = grey(0.9))
      panel.barplot(x, y, ...)
      panel.key(..., cex = 0.7, points = FALSE)
    }
  )
```


### Trends in protein utilization hint towards flux control

The first task is to make a simple assessment of trends in protein abundance for simulation and experimental results.
One completely supervised strategy could for example entail the summarization of each protein's abundance over growth rate by fitting a linear regression model. One could then coarsely cluster (or hand pick) groups of proteins that will

- increase in simulation, increase in experiment
- increase in simulation, decrease/are constant in experiment
- ...






---
title: "Constraints for an *R. eutropha* resource allocation model"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_notebook: 
    theme: spacelab
    toc: yes
---


## Description

This R notebook is a bioinformatics pipeline to **collect constraints for a genome scale, resource allocation model** in the chemolithoautotroph *Ralstonia eutropha* (a.k.a. *Cupriavidus necator*).

A resource allocation model can be coarse-grained (few symbolic reactions) or have genome scale detail (all known biochemical reactions and their associated genes). However, both types of models need to be constrained by a set of parameters to make realistic predictions. Depending on the model frame work, constraints can be equality constraints (example: turnover number of an enzyme E kcat<sub>E</sub> = 100 s<sup>-1</sup>), or inequality constraints (0 s<sup>-1</sup> <= kcat<sub>E</sub> <= 100 s<sup>-1</sup>). 

This notebook has the purpose to collect **constant and growth-rate dependent constraints** as they are used in [RBA models](https://sysbioinra.github.io/RBApy/). In RBApy, apparent enzyme efficiencies (_kapp_), protein abundance, molecular machine abundance (protein/macromolecule complexes), and fluxes can be constrained. RBApy has the following possibilities for custom constraints.

- constants (example: `A = 0.1`)
- linear relationship, e.g. with growth rate µ (example: `B = 2 * µ + 0.1`)
- Michaelis-Menthen like kinetics for kapp (example: `kapp = kcat * [S] / ([S] + Km)`)

Different types of data were collected to constrain at least two major determinants of a resource allocation model.

1. **turnover number `kcat`**: Organism-specific values can be downloaded from enzyme data base BRENDA. In this case we use a precompiled file `max_KCAT.txt` from another resource allocation algorithm, [GECKO](https://github.com/SysBioChalmers/GECKO/tree/master/databases)
2. **protein abundance**: protein abundance was determined with mass spcetrometry globally for *R. eutropha* using different growth rates and carbon sources. This data will be used to estimate and constrain enzyme abundance, and non-enzyme protein abundance.


## Libraries

```{r, message = FALSE}
# loading libraries
library(lattice)
library(latticeExtra)
library(latticetools)
library(tidyverse)
library(stringi)
```

## Turnover numbers

### Import data from GECKO

The precompiled turnover numbers were downloaded from [GECKO](https://github.com/SysBioChalmers/GECKO/tree/master/databases) and apparently created Aug 16, 2018. The table contains all possible kcat values per enzyme class. It also contains a rudimentary phylogenetic classification (bacteria, archae, eukaryota, and so on) that can be used to strip matching kcat values with regular expressions.

```{r, message = FALSE, warning = FALSE}
# load kcat data
df_kcat <- read_tsv("../data/GECKO_20200505_max_KCAT.tsv", col_names = FALSE)[-5] %>%
  set_names(c("EC_number", "substrate", "organism", "kcat"))

# preview data
head(df_kcat)
```

### Overview of kcat values

The first step is to reformat the data to a more usable shape. Then, we extract species annotation using regular expressions, and plot an examplary subset of the data. The goal here is to test if the kcat values are normal-distributed, if there are outliers, and how common outliers are for specific species or EC numbers. These precautions are taken to make sure that the (maximum) kcat values we select are representative, and not extreme measurements that are unlikely to exist under unphysiological conditions (most values in BRENDA are inferred from *in vitro* measurements though).

```{r}
# split organism column in three
df_kcat <- df_kcat %>% separate(organism, c("species", "phylogeny", "org_id"), sep = "//") %>%
  
  # replace placeholder star with NA
  mutate_all(function(x) na_if(x, "*")) %>%
  
  # clip 'EC' away from EC number
  mutate(EC_number = gsub("^EC", "", EC_number))

head(df_kcat)
```

Now that the data is in a reasonable shape, `kcat` value distributions can be plotted broken down by EC number, substrate or organism.

```{r, fig.width = 9, fig.height = 7}
df_kcat <- df_kcat %>% 
  
  # determine number of values per reactions
  group_by(EC_number) %>%
  mutate(n_kcat_values = length(kcat))
  
# plot
histogram(~ log10(kcat) | EC_number, 
  filter(df_kcat, n_kcat_values >= 75),
  as.table = TRUE, between = list(x = 0.5, y = 0.5),
  par.settings = custom.lattice, border = "white",
  scales =list(alternating = FALSE), ylim = c(-5, 60),
  panel = function(x, ...){
    panel.grid(h = -1, v = -1, col = grey(0.9))
    panel.histogram(x, ...)
  }
)
```

It becomes quite clear that some of the kcat value distributions contain extreme outliers (1 to 2 orders of magnitude). Extreme values are biologically possible because the kcat can be different for different substrates or organism. Nevertheless it is wise to focus on the majority vote, and exclude kcat values that deviate too much. We filter the 5 % upper and lower quantile if more than 5 kcat values are available per reaction.

```{r, fig.width = 9, fig.height = 7}
df_kcat <- df_kcat %>%
  
  # filter the central 90 % of values (discard upper and lower 5 %)
  filter(!(n_kcat_values >= 5 & 
    (kcat < quantile(kcat, 0.05) | kcat > quantile(kcat, 0.95))
  ))

# plot
histogram(~ log10(kcat) | EC_number, 
  filter(df_kcat, n_kcat_values >= 75),
  as.table = TRUE, between = list(x = 0.5, y = 0.5),
  par.settings = custom.lattice, border = "white",
  scales =list(alternating = FALSE), ylim = c(-5, 60),
  panel = function(x, ...){
    panel.grid(h = -1, v = -1, col = grey(0.9))
    panel.histogram(x, ...)
  }
)
```

### Function to retrieve kcat values as model constraints

The last step is to devise a function that will match annotated EC numbers from the metabolic model with kcat values from the BRENDA database. It needs to perform the following steps sequentially. For each enzyme E, 

1. look up possible EC numbers in data base
2. if a *Ralstonia*/*Cupriavidus* entry is available, choose it
3. else look up *Burkholderiales* and take the median of the subset
4. else look up *betaproteobacteria* and take the median of the subset
5. else if none of these categories are available, take the median of all

The function is implemented in a versatile self-contained way so that it can be reused and adapated any time.
It takes the following input parameters:

- `kcat_data` - data frame with kcat values (imported directly from GECKO). Needs at least columns 'EC_number', 'species', 'phylogeny', and 'kcat'
- `ec_number` - the EC number to look up
- `species` - the name of the target species
- `phylogeny` - a set of search terms to look up in order of decreasing specificity
- `fun_aggregate` - the function to aggregate a selection of kcat values, like max, mean, median, and so on

```{r}
# main retrieval function
get_kcat <- function(
  ec_number, kcat_data,
  species = NULL, phylogeny = NULL,
  fun_aggregate = median) {
  
  # remove NA kcats from input and filter by EC number
  kcat_data <- kcat_data %>% ungroup %>%
    filter(!is.na(kcat), EC_number %in% ec_number)
  
  # return NA if EC number is not present
  if (nrow(kcat_data) == 0) {
    return(NA)
  }
  
  # filter by species
  index <- FALSE
  if (!is.null(species)) {
    index <- grepl(species, kcat_data[["species"]])
    if (any(index)) kcat_data <- filter(kcat_data, index)
  }
  
  # filter by phylogenetic terms
  if (!is.null(phylogeny) & !any(index)) {
    for (key in phylogeny) {
      index <- grepl(key, kcat_data[["phylogeny"]])
      if (any(index)) kcat_data <- filter(kcat_data, index); break
    }
  }
  
  # aggregate values
  kcat_data %>% pull(kcat) %>% fun_aggregate
}
```

Now let's test function using regular expressions!

```{r}
get_kcat(
  ec_number = "1.1.1.1",
  kcat_data = df_kcat,
  species = "[Cc]upriavidus|[Rr]alstonia",
  phylogeny = c("[Bb]urkholderiales", "[Bb]etaproteobacteria")
)
```

### Retrieve kcat values and export

The final step is to apply the function to each EC number that is present in the model. We retrieve only **full matches**, not partial matches like `1.2.3.-`. We retrieve the **minimum, median, and maximum kcat values** per reaction if several are available. Depending on the issue of over-constraining a resource allocation model, we can select the optimal/most realistic option. 

```{r, message = FALSE, warning = FALSE}
# load model reactions
df_model <- read_csv("../data/model_reactions.csv")[-1]
head(df_model)

# preprocessing EC numbers
df_model <- df_model %>%
  mutate(EC_number = EC_number %>% 
    str_replace_all("\\[|\\]|'", ""))

# retrieve kcat values and add new column to reaction data
for (fn in c("min", "median", "max")) {
  df_model[[paste0("kcat_", fn)]] <- sapply(
    df_model$EC_number, USE.NAMES = FALSE, function(ec_number) {
      ec_number %>% str_split(", ") %>% unlist %>%
      get_kcat(
        df_kcat,
        fun_aggregate = get(fn),
        species = "[Cc]upriavidus|[Rr]alstonia", 
        phylogeny = c("[Bb]urkholderiales", "[Bb]etaproteobacteria")
      )
    }
  )
}
```

Next we will have a look at the distribution of the retrieved minimal, maximal and median `kcat` values. We plot the distribution of `kcat` values on a log10 scale. The spread of `kcat` values is on average around 2 orders of magnitude between minimum and maximum (global medians around 1, 10, 100, see figure below). From the quantile analysis it seems that the central 75 % of `kcat` values lie between 2 and 53 with a global median of 11.1 1/s (median kcats). This is extremely close to an average default kcat of 12.5 1/s suggested in Bulovic et al., 2019, but lower than the default values used in CobraME (65 1/s) and ETFL (172 1/s).

```{r, fig.width = 8}
# overview about kcat value distribution
histogram(~ kcat_min + kcat_median + kcat_max, 
  df_model,
  breaks = seq(-7, 7, 0.3), 
  par.settings = custom.lattice, border = "white",
  scales = list(alternating = FALSE, x = list(log = 10)),
  panel = function(x, ...){
    panel.grid(h = -1, v = -1, col = grey(0.9))
    panel.abline(v = -7:7, col = grey(0.9))
    med = median(x, na.rm = TRUE)
    panel.abline(v = med, col = grey(0.4), lty = 2, lwd = 1.5)
    panel.text(-4, 3, label = paste0("m = ", round(10^med, 3), " 1/s"), col = grey(0.4))
    panel.histogram(x, ...)
  }
)

# use quantiles on log 10 scaled kcats and scale back 
# (we want data normally distributed)
quantile(log10(df_model$kcat_median), na.rm = TRUE) %>% {10^.}
```

---------

The final step is to export the data frame in a format that is suitable for RBApy input. In this case the format requirements are:

- tab-separated values, no header
- units in `1/h` instead of `1/s` (x 3600)
- reaction ID in column 1, format (`R_`)`ID_enzyme` or `ID_transporter`
- max kcat in column 2
- min kcat in column 3 (backward efficiency, can be identical)
- no NA values (only complete rows)

```{r}
df_export <- df_model %>%
  select(reaction_id, kcat_median) %>% rename(kcat = kcat_median) %>%
  mutate(reaction_id = paste0("R_", reaction_id, "_enzyme")) %>%
  mutate(kcat = kcat * 3600, kcat_2 = kcat) %>%
  filter(!is.na(kcat))

write_tsv(df_export, "../data/enzyme_efficiency.tsv", col_names = FALSE)
```

```{r, include = FALSE}
# also export directly to RBA model folder
write_tsv(df_export, "../../../../Models/Bacterial-RBA-models/Ralstonia-eutropha-H16/data/enzyme_efficiency.tsv", col_names = FALSE)
```

----------

## Fraction of protein per compartment

The RBA model takes as another input parameter (or constraint) the fraction of protein per compartment. This constraint is important as it allows the cell to have only a limited amount of protein in cytoplasm or membrane compartments, for example. This constraint can be constant or it can be growth rate dependent e.g. by a linear relationship. The RBA modeling framework contains a function to estimate fraction of protein per compartment using input data that is available:

- `Experiment` - cultivations with different known growth rates (steady state)
- `ProteinData` - protein abundances (estimated using MS)
- `LocationData` - protein localization (annotated and predicted)

We re-format available data to the standard required by `RBApy/estim`, see RBApy manual for details. THe first step is to prepare cultivation data with growth rates. We focus on the standard condition as a training data set (fructose as carbon source, no NH4+ limitation).

```{r}
df_experiment <- data.frame(
  Experiment_ID = paste0("FRC ", c(0.05,0.1, 0.15, 0.2, 0.25)),
  growth_rate = c(0.05, 0.1, 0.15, 0.2, 0.25)
)
```

The next step is to prepare a table with protein abundance and localization. Protein abundance can be in any unit according to the RBApy manual, but it's best to use `mol fraction` instead of `mass fraction` as all other RBApy functions also use `mmol`. The `mol fraction` is already available in the processed data set.

```{r}
# import proteomics data
load("~/Documents/SciLifeLab/Resources/R_projects/ShinyProt/data/Ralstonia_eutropha.Rdata")

# filter only required conditions
df_protein <- Ralstonia_eutropha %>% filter(grepl("FRC ", condition)) %>%
  
  # select only required columns and spread to long format
  select(condition, locus_tag, growthrate, Psortb_localization, mol_fraction) %>%
  set_names(c("condition", "protein", "growthrate", "location", "mol_fraction")) %>%
  
  # match localization names to model, simplify
  mutate(location = recode(location, Unknown = "Cytoplasm", Cytoplasmic = "Cytoplasm")) %>%
  mutate(location = replace(location, location != "Cytoplasm", "Cell_membrane"))

head(df_protein)
```

Now we can summarize the data by taking the sum of `mol fraction` over conditions and localizations. A simple approach to finding linear functions, where all proteins of all locations sum to one for a specific growth rate, would be to fit linear models for all compartments esxcept one (e.g. cytoplasmic proteins, the major compartment). This one will then get a linear model fitted from the residual protein mass. We expect the error for `Cytoplasm` to be very small, as it is the biggest compartment. However it turned out that the linear models fitted to both compartments perfectly sum to one.

```{r, fig.width = 6, fig.height = 3.5}
df_prot_per_comp <- df_protein %>% 
  group_by(growthrate, location) %>%
  summarize(prot_per_compartment = sum(mol_fraction, na.rm = TRUE))

# we can see a slight increase in cytoplasmic proteins
# and decrease in cell membrane proteins with rowth rate
xyplot(prot_per_compartment ~ growthrate | location, 
  df_prot_per_comp,
  groups = location, ylim = c(-0.1, 1.1),
  par.settings = custom.lattice,
  scales = list(alternating = FALSE),
  panel = function(x, y, ...){
    panel.grid(h = -1, v = -1, col = grey(0.9))
    panel.xyplot(x, y, ...)
    panel.lmlineq(x, y, r.squared = TRUE, 
      fontfamily = "FreeSans", pos = 3, offset = 0.6, ...)
  }
)

# The two models sum to one for any rbitrary growth rate
fit_cell_membrane = function(mu) 0.152 - 0.178*mu
fit_cytoplasm = function(mu) 0.848 + 0.178*mu

print(fit_cell_membrane(0.123) + fit_cytoplasm (0.123))

```




